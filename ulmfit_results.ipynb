{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ulmfit-results.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05K3_EAHUJwD",
        "colab_type": "text"
      },
      "source": [
        "## ULMFiT Results and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBslzrlAXIH8",
        "colab_type": "text"
      },
      "source": [
        "Code to import the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeExVbcUVwZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "089f7be4-a8a0-4a1c-bb78-cc8d3ebf5c23"
      },
      "source": [
        "# allow us to import data from Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# make our root and base directories clear\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'Fellowship-ai-challenge/'\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(base_dir + 'Tweets.csv')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_FM79apXV7g",
        "colab_type": "text"
      },
      "source": [
        "Code to preprocess Twitter data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttkZRKDWXM03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def removeUnicode(text):\n",
        "  \"\"\" Removes unicode strings like \"\\u002c\" and \"x96\" \"\"\"\n",
        "  text = re.sub(r'(\\\\u[0-9A-Fa-f]+)',r'', text)       \n",
        "  text = re.sub(r'[^\\x00-\\x7f]',r'',text)\n",
        "  return text\n",
        "  \n",
        "def replaceURL(text):\n",
        "  \"\"\"Replaces url address with \"url\" \"\"\"\n",
        "  text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','url',text)\n",
        "  text = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
        "  return text\n",
        "\n",
        "def replaceAtUser(text):\n",
        "  \"\"\" Replaces \"@user\" with \"atUser\" \"\"\"\n",
        "  # text = re.sub('@[^\\s]+','atUser',text)\n",
        "  text = re.sub('@[^\\s]+','',text)\n",
        "  return text\n",
        "\n",
        "def removeHashtagInFrontOfWord(text):\n",
        "  \"\"\" Removes hastag in front of a word \"\"\"\n",
        "  text = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
        "  return text\n",
        "\n",
        "def removeNumbers(text):\n",
        "  \"\"\" Removes integers \"\"\"\n",
        "  text = ''.join([i for i in text if not i.isdigit()])         \n",
        "  return text\n",
        "\n",
        "def removeEmoticons(text):\n",
        "  \"\"\" Removes emoticons from text \"\"\"\n",
        "  text = re.sub(':\\)|;\\)|:-\\)|\\(-:|:-D|=D|:P|xD|X-p|\\^\\^|:-*|\\^\\.\\^|\\^\\-\\^|\\^\\_\\^|\\,-\\)|\\)-:|:\\'\\(|:\\(|:-\\(|:\\S|T\\.T|\\.\\_\\.|:<|:-\\S|:-<|\\*\\-\\*|:O|=O|=\\-O|O\\.o|XO|O\\_O|:-\\@|=/|:/|X\\-\\(|>\\.<|>=\\(|D:', '', text)\n",
        "  return text\n",
        "\n",
        "\n",
        "\"\"\" Replaces contractions from a string to their equivalents \"\"\"\n",
        "contraction_patterns = [ (r'won\\'t', 'will not'), (r'can\\'t', 'cannot'), (r'i\\'m', 'i am'), (r'ain\\'t', 'is not'), (r'(\\w+)\\'ll', '\\g<1> will'), (r'(\\w+)n\\'t', '\\g<1> not'),\n",
        "                         (r'(\\w+)\\'ve', '\\g<1> have'), (r'(\\w+)\\'s', '\\g<1> is'), (r'(\\w+)\\'re', '\\g<1> are'), (r'(\\w+)\\'d', '\\g<1> would'), (r'&', 'and'), (r'dammit', 'damn it'), (r'dont', 'do not'), (r'wont', 'will not') ]\n",
        "def replaceContraction(text):\n",
        "  patterns = [(re.compile(regex), repl) for (regex, repl) in contraction_patterns]\n",
        "  for (pattern, repl) in patterns:\n",
        "      (text, count) = re.subn(pattern, repl, text)\n",
        "  return text\n",
        "\n",
        "def preprocessTwitterData(df):\n",
        "  \"\"\"Function to apply text preprocessing functions to a dataframe\"\"\"\n",
        "  \n",
        "  # remove unicode\n",
        "  df['text'] = df['text'].apply(removeUnicode)\n",
        "  \n",
        "  # replace url\n",
        "  df['text'] = df['text'].apply(replaceURL)\n",
        "  \n",
        "  # replace '@' signs\n",
        "  df['text'] = df['text'].apply(replaceAtUser)\n",
        "  \n",
        "  \n",
        "  # replace hastags\n",
        "  df['text'] = df['text'].apply(removeHashtagInFrontOfWord)\n",
        "  \n",
        "  # remove numbers in the tweets\n",
        "  df['text'] = df['text'].apply(removeNumbers)\n",
        "  \n",
        "  # remove the emoticons\n",
        "  df['text'] = df['text'].apply(removeEmoticons)\n",
        "  \n",
        "  # replace contractions\n",
        "  df['text'] = df['text'].apply(replaceContraction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdP0RJCdXuyS",
        "colab_type": "text"
      },
      "source": [
        "## Functions to produce results fast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc8StDeoUAkR",
        "colab_type": "text"
      },
      "source": [
        "Now that we've described and explained the entire process, in order to get eventually get the best results, we need to test out various hyperparameters.\n",
        "\n",
        "Let's define a function that can take in these hyperparameters as variables, and we can simply run the function once to do our entire analysis in one go.\n",
        "\n",
        "It would be helpful to see a confusion matrix for each individual category so we can so let's define functions to plot the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OlxoEt3JqHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import relevant libs\n",
        "from fastai.text import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def ULMFiT_Airline_Sentiment(df,test_size=0.1, valid_size=0.1,preprocess=True,\n",
        "                            lm_dropout=0.3,classifier_dropout=0.5,\n",
        "                            max_lr_lm=1e-2,num_cycles_lm_ft=5,\n",
        "                            bs_classifier=32,\n",
        "                            lr_classifier_init=1e-2,\n",
        "                             epochs_classifier_init=5,\n",
        "                             lr_classifier_1=5e-3,\n",
        "                             epochs_classifier_1=5,\n",
        "                             lr_classifier_2=5e-3,\n",
        "                             epochs_classifier_2=5,\n",
        "                             lr_classifier_final=5e-3,\n",
        "                             epochs_classifier_final=5\n",
        "                            ):\n",
        "  \"\"\"\n",
        "  Function to apply ULMFiT model to the Airline Sentiment\n",
        "  \n",
        "  @df: The dataframe with the data\n",
        "  @test_size: how much data to set aside as test set\n",
        "  @valid_size: how much data to set aside from training as validation set\n",
        "  @preprocess: whether or not to preprocess the tweet data\n",
        "  @lm_dropout: dropout to apply to the language model when fine-tuning\n",
        "  @classifier_dropout: dropout to apply to the classifier when fine-tuning\n",
        "  @max_lr_lm: the max learning rate for 1cycle pol. on LM\n",
        "  @num_cycles_lm_ft: the number of epochs we use to train the LM after\n",
        "  unfreezing.\n",
        "  @bs_classifier: batch size for classifier\n",
        "  @lr_classifier_init: learning rate for first training of classifier\n",
        "  @epochs_classifier_init: number of epochs we use to train the classifier\n",
        "  before gradual unfreezing\n",
        "  @lr_classifier_1:learning rate for training of classifier after 1st unfreeze\n",
        "  @epochs_classifier_1:number of epochs \"                              \"\n",
        "  @lr_classifier_2:learning rate for training of classifier after 2nd unfreeze\n",
        "  @epochs_classifier_2: number of epochs \"                             \"\n",
        "  @lr_classifier_final: learning rate after entire model unfrozen\n",
        "  @epochs_classifier_final:epochs \"                         \"\n",
        "  \"\"\"\n",
        "  # preprocessing data\n",
        "  if preprocess:\n",
        "    print(\"preprocessing Twitter data\")\n",
        "    preprocessTwitterData(df)\n",
        "  \n",
        "  # only need text and airline_sentiment\n",
        "  df = df[['text','airline_sentiment']]\n",
        "  \n",
        "  # split the data into train and test\n",
        "  df_train, df_test = train_test_split(df,test_size=test_size,random_state=40)\n",
        "  \n",
        "  # Convert the cleaned training and testing data\n",
        "  # into their own CSV files which we can import\n",
        "  # later to perform modeling on them\n",
        "\n",
        "  # these lines write CSV files to our current directory\n",
        "  df_train.to_csv('twitter_data_cleaned_train.csv')\n",
        "  df_test.to_csv('twitter_data_cleaned_test.csv')\n",
        "  \n",
        "  print(\"Getting LM data into appropriate form\")\n",
        "  # TextMLDataBunch process\n",
        "  data_lm = TextLMDataBunch.from_csv(path='',\n",
        "                                     csv_name='twitter_data_cleaned_train.csv',\n",
        "                                     valid_pct=valid_size)\n",
        "  \n",
        "  \n",
        "  # LM learner\n",
        "  learn = language_model_learner(data_lm,AWD_LSTM,drop_mult=lm_dropout)\n",
        "  \n",
        "  print(\"Fine-tuning language model\")\n",
        "  # one cycle training, always use moms=(0.85,0.75), always use one epoch on\n",
        "  # this step to avoid overly fine-tuning\n",
        "  learn.fit_one_cycle(1,max_lr=max_lr_lm)\n",
        "  \n",
        "  # unfreeze LM and do discriminative fine-tuning\n",
        "  learn.fit_one_cycle(cyc_len=num_cycles_lm_ft, \n",
        "                      max_lr=slice(max_lr_lm/(2.6**4),max_lr_lm))\n",
        "  \n",
        "  # save the encoding layer\n",
        "  learn.save_encoder('encoder')\n",
        "  \n",
        "  print(\"LM fine-tuning complete\")\n",
        "  # Start Classifier fine-tuning\n",
        "  \n",
        "  print(\"Getting Classifier data into appropriate form\")\n",
        "  data_class = TextClasDataBunch.from_csv(path='',\n",
        "                                          csv_name='twitter_data_cleaned_train.csv',\n",
        "                              vocab=data_lm.train_ds.vocab,\n",
        "                                          bs=bs_classifier\n",
        "                                          ,text_cols='text'\n",
        "                                          ,label_cols='airline_sentiment')\n",
        "  \n",
        "  # Classifier Learner\n",
        "  learn = text_classifier_learner(data_class,AWD_LSTM,\n",
        "                                  drop_mult=classifier_dropout)\n",
        "  \n",
        "  # Load the pretrained encoder into the model\n",
        "  learn.load_encoder('encoder')\n",
        "  \n",
        "  print(\"Started Classifier fine-tuning\")\n",
        "  # Training before gradual unfreezing\n",
        "  learn.fit_one_cycle(epochs_classifier_init,lr_classifier_init)\n",
        "  \n",
        "  print(\"Started gradual unfreezing\")\n",
        "  # Start gradual unfreezing process\n",
        "  \n",
        "  # unfreeze next layer and train (discriminative layer training)\n",
        "  learn.freeze_to(-2)\n",
        "  learn.fit_one_cycle(epochs_classifier_1,\n",
        "                      slice(lr_classifier_1/(2.6**4),lr_classifier_1))\n",
        "  \n",
        "  # unfreeze next layer and train (discriminative layer training)\n",
        "  learn.freeze_to(-3)\n",
        "  learn.fit_one_cycle(epochs_classifier_2,\n",
        "                      slice(lr_classifier_2/(2.6**4),lr_classifier_2))\n",
        "  \n",
        "  # unfreeze everything and train\n",
        "  learn.fit_one_cycle(epochs_classifier_final,\n",
        "                      slice(lr_classifier_final/(2.6**4),lr_classifier_final))\n",
        "  \n",
        "  print(\"ULMFiT done!\")\n",
        "  # return the model\n",
        "  return learn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Taken from the scikit-learn documentation\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    #classes = classes[unique_labels(y_true, y_pred)]\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVRvrxlCUq4r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46f97e03-13c2-4d0b-a44c-3e6065b55146"
      },
      "source": [
        "# example of using the function with accuracy and confusion matrix\n",
        "\n",
        "# import metrics from sklearn\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# apply function to get learner\n",
        "learn = ULMFiT_Airline_Sentiment(df,preprocess=False)\n",
        "\n",
        "# put test data in test df\n",
        "df_test = pd.read_csv('twitter_data_cleaned_test.csv')\n",
        "\n",
        "# add a column with the predictions on the test set\n",
        "df_test['sentiment_pred'] = df_test['text'].apply(lambda row:str(learn.predict(row)[0]))\n",
        "\n",
        "\n",
        "# print the accuracy against the test set\n",
        "print(\"Accuracy: {}\".format(accuracy_score(df_test['airline_sentiment'],df_test[\n",
        "    'sentiment_pred'\n",
        "])))\n",
        "\n",
        "# plot the confusion matrix for the test set\n",
        "plot_confusion_matrix(df_test['airline_sentiment'],df_test['sentiment_pred'],\n",
        "                      classes=['negative','neutral','positive'])\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started Classifier fine-tuning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.684226</td>\n",
              "      <td>0.584143</td>\n",
              "      <td>0.758346</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.700332</td>\n",
              "      <td>0.555559</td>\n",
              "      <td>0.767071</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.646435</td>\n",
              "      <td>0.533771</td>\n",
              "      <td>0.786798</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.639386</td>\n",
              "      <td>0.541082</td>\n",
              "      <td>0.773520</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.625220</td>\n",
              "      <td>0.530479</td>\n",
              "      <td>0.777693</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Started gradual unfreezing\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.615485</td>\n",
              "      <td>0.511355</td>\n",
              "      <td>0.798938</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.617296</td>\n",
              "      <td>0.519167</td>\n",
              "      <td>0.790592</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.571508</td>\n",
              "      <td>0.485129</td>\n",
              "      <td>0.809560</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.510683</td>\n",
              "      <td>0.474465</td>\n",
              "      <td>0.810698</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.475067</td>\n",
              "      <td>0.474577</td>\n",
              "      <td>0.810319</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.475503</td>\n",
              "      <td>0.465757</td>\n",
              "      <td>0.812216</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.541642</td>\n",
              "      <td>0.471177</td>\n",
              "      <td>0.820561</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.423801</td>\n",
              "      <td>0.471732</td>\n",
              "      <td>0.819803</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.321694</td>\n",
              "      <td>0.500005</td>\n",
              "      <td>0.821320</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.252500</td>\n",
              "      <td>0.505723</td>\n",
              "      <td>0.824355</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.282763</td>\n",
              "      <td>0.513888</td>\n",
              "      <td>0.815250</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.349025</td>\n",
              "      <td>0.564520</td>\n",
              "      <td>0.816009</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.280702</td>\n",
              "      <td>0.532669</td>\n",
              "      <td>0.816009</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.199209</td>\n",
              "      <td>0.589608</td>\n",
              "      <td>0.810698</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.132459</td>\n",
              "      <td>0.595762</td>\n",
              "      <td>0.821700</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "ULMFiT done!\n",
            "Accuracy: 0.828551912568306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEYCAYAAADLZOR0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJPpc6xYZpLF",
        "colab_type": "text"
      },
      "source": [
        "# Analysis of results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-jalPewhpXZ",
        "colab_type": "text"
      },
      "source": [
        "### Why accuracy as a metric?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFgUDvNchuXK",
        "colab_type": "text"
      },
      "source": [
        "We could use other classification metrics (such as recall, precision, etc.) but we're mostly interested in seeing how our results compare to other models. Both online and in research papers, these models' effectiveness are typically measured with accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW7fm2gjimQ-",
        "colab_type": "text"
      },
      "source": [
        "### Results from other baseline models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNaxoyS3ipkL",
        "colab_type": "text"
      },
      "source": [
        "We're trying to gauge the effectiveness of ULMFiT, so it's important to measure our results against other common baselines models. \n",
        "\n",
        "From Kaggle (all are accuracies on testing sets):\n",
        "- Random Forest: 81.3%\n",
        "- AdaBoost:78.6%\n",
        "- Keras deep learning: 77.9%\n",
        "- Linear SVM: 78.5%\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dZDwuxrlxsr",
        "colab_type": "text"
      },
      "source": [
        "### Our results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlgfEU4vl6CP",
        "colab_type": "text"
      },
      "source": [
        "As shown above, our accuracy on the testing set was **82.9%**. This is a slight improvement from the top score (amongst baseline ML models). The process of tuning the hyperparameters was done through trial and error/rerunning the Google Colab notebook. \n",
        "\n",
        "Most of the hyperparameter tunings (such as individual learning rates for the gradual unfreezes) resulted in negligible changes in accuracy. Increasing the epochs for different training rounds usually resulted in overfitting, which confirms Jeremy Howard's point about overly aggressive fine-tuning. \n",
        "\n",
        "Surprisingly, however, **preprocessing the Twitter data resulted in noticeably worse results (about 1-2% changes in accuracy).** This could be because of poor preprocessing techniques. It could also be because of our preprocessing techniques clashing with those of the fastai library.\n",
        "\n",
        "From the confusion matrix, we can see that there were quite a few samples that we predicted negative, when they were actually neutral. Thus, the model is slightly biased towards predicting a negative sentiment: this might have to do with the fact that there are so many negative Tweets in the first place.\n",
        "\n",
        "Overall, our results were better than those of most baseline models. This is likely due to the relevant features learned by the pretrained language model. Furthermore, our fine-tuning process was simple and computationally efficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTvwKqnDZv25",
        "colab_type": "text"
      },
      "source": [
        "## Possible improvements/weaknesses of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6433EtUZzKo",
        "colab_type": "text"
      },
      "source": [
        "- We didn't exhaust all of our possible ways of preprocessing the Twitter data. In fact, taking preprocessing out gave us better results. Perhaps we could investigate more about preprocessing data in order to improve the results.\n",
        "- We used the implementation inside the fastai library for our pretrained language model. As a result, we couldn't make that many tweaks to it (such as taking out a particular dropout) that might improve performance for this particular dataset. In the future, we may benefit from implementing part of the model from scratch.\n",
        "- If we acquire a better language model, we might be able to improve our results. Perhaps we could integrate a model such as BERT (Google) or GPT-2 to do transfer learning with ULMFiT.\n",
        "- We didn't have an efficient way of exploring different hyperparameters aside from doing trial and error. In the future, we could use a customized function and advanced computational resources to explore a greater set of hyperparameters.\n",
        "\n",
        "Ultimately, the best two directions for improving our results, as well as text classification results in general are:\n",
        "- **Finding more sophisticated ways to create language models that beat the state-of-the art.**\n",
        "- **Researching more about transfer learning in general, so we can improve our understanding of ULMFiT and craft better ways of fine-tuning the model.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U1w8H4FZq0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}